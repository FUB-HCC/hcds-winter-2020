# Summary Questions - Podcast: Judea Pearl

1. In the conversation they talk also about the Do-Operator. What is the Do-Operator. I'v got a very basic Idea of it but definitely need to read more about it. 
2. Is it possible to formulate everything question in a mathematical question?

***

1. Can you express every question mathematically?

**Why:** The interviewee got asked what is a good way to do a reasearch. He responded with we should state every question mathimatically first before trying to find an answer. 

***

1. Can we use Metaphors to increase the interpretability of our models? According to Judea, Metaphors are a strong tool that help us to understand new problems by mapping them to known problems. I could imagine, that they can be applied to achieve interpretability.
1. (How exactly does the do-operator work? They seem to be an important concept but it was hard for me to understand these operators by listening to the podcast.)

***

1. How can we identify causal effects?

**Why:** As computing increasingly impact all parts of life, questions of cause-and-effect are critical for the design and data-driven evaluation of all the applications we build. 


***

1. There was the Do()-Operator mentioned. What is meant by that?

***

1. Should it really be the goal to replicate human intelligence or should we just accept that it will be not possible due to the limited understanding of the human brain and conciousness and focus our energy of different aspects of artifical intelligence research? 

***

1. Is there such a thing as actual free will, or is it really just an illusion, that we let ourselves believe is true ?
2. Why is it so hard for machines / models to follow back a given causal "line", and inferr causes for other, but related outputs ?
3. Is intellegence only about how much knowlegde is available and how well it can be merged together to create new knowledge ?

***

1. Is a Bayesian network a starting point for a machine with causal reasoning? Or isn't it just another data-centered approach?

**Why:** I would like to know more about examples of current algorithms that include a sort of causal reasoning.

2. If we can build a computer with causal reasoning, causal inference, etc. do we than really have human level inteligence?

**Why:** I am not sure if this is the final approach to human iteloligence.

***

1. I have a difficult time understanding how one can quantify parameters (that are neccessary to model a situation) that have been unquantified before? Who decides that this might be a good quantification of different parameters and how can you be sure that they are not correlating with each other. In order create a model you have to generalize aspects. Is there a way to make sure you are not neglecting aspects that might've been suuuper important later but did not show any relevance when modelling?
1. Also I feel like it might be difficult to investigate causes of a specific phenomena when you use the "representation first, discovery second" approach?

***

1. What is intelligence? Should we call "artificial intelligence" intelligence or is it too different? How can we define the terms if not even the human sciences agree on one clear definition of "human intelligence"?

2. How to solve the problem of causal relation if we do not have enough data and can only conclude from correlations? Should we just accept it as it is and work with correlations or should we try to generate more experiments which allow causal relations? Or are correlations good enough in many cases?

***

1. How do we manage to find a mathematical formulation of every complex problem that has to be researched/understood?

**Why:** Judea Pearl mentioned, that to do good research it is important to formulate a problem in a mathematical manner, but I don't how this could be achieved 
for every problem or wether this is even possible.

***

1. I have some difficulties to understand the concept "metaphor". It sounds for me more like a philosophical or literary concept. Prof. Pearl described metaphor as a way of learning knowledge of new domain by referring them to similar domains which we are familiar with. Then what is the difference between metaphor and transfer learning? How to do the mapping from one domain to another domain? How to evaluate if the metaphor is acceptable or "good" enough when we don't have enough data in a new domain or don't have suitable labels for data? 
2. This is my personal confusion and I am currently even unable to formulate a suitable well-defined question. Is it essential to find out every causal relation behind a machine learning task? (Or how do we know for what task there IS actually a causal effect behind). Because we know that people are not rational at all, even though we somehow have the "rationale assumption" (at least in economics). Somehow we can not always find a causal relation behind intention and outcomes. Or some causes are more personal and emotional which is quite difficult to even observed, let alone measured. Additionally, people learn by imitating as a baby, which seems just like the curve fitting in machine learning. In human science, some causes may be just "added" artificially afterwards. 
