# Summary Questions Podcast
https://www.datacamp.com/community/podcast/human-centered-design-data-science
***
The _Cookiecutter Data Science project_, Peter Bull introduces in the podcast seems to be from my understanding
something like a framework which provides a structure for a data science project. I wonder how much companies
make use of such frameworks and if also commercial companies make use of it? 
***
1. Is it possible to create machine models completely free from bias?
2. If so how?
3. If not how can we deal with it?
4. How does data ethics influence the data science process?
***
1. In the beginning they spoke about best practices in data science, so I'm now wondering if there is a good collection out there.
2. They talked about that empathy is a core skill for data scientist and that one should approach to solve tasks with the attitude of problem first rather than method first. There they didn't mention if this was something that is thought in general in university or if this is a skill that just some individuals thought themselves.

A bit off-topic but I liked how they mentioned that they use a similar approach to the folder structure for data science projects as in software engineering.
***
1. How do standardized structured data science projects support HCDS?

I think structured projects are very useful in general and it is important to learn about that and reproducability. I would like to know more about the connection between standardized data science projects and HCDS.
***
1. How can machines take over a process both effectively and ethically? (referring to bias in data)
2. "We can't even get this tool installed" was mentioned while talking about team collaboration. I definitely feel that. How can we improve the user friendliness for team projects? 
***
1. How starry-eyed is the statement that 'going where the data originates from' is possible in nearly every case? I think it is a great idea to do that but not possible in a lot of projects for various reasons. Maybe observing the data collection may even introduce new problems where the researcher believes some date is false/incomplete/etc. because of statements from involved persons which might be very subjective.
2. When the topic of 'models you can trust' came up I was wondering how transparent e. g. deep learning algorithms actually are, since I do not have any experience in this field. So my question would be if it's even possible to develop models and algorithms you can 'trust' if they might behave like a blackbox, or if the missing trust originates from choices of the developer/researcher?
***
What is meant by "empathy" as a necessary skill for data scientists?
Does ist just mean that data scientists have to be able to identify with the problems and projects they are working with? Or that we need a solid value system and always reflect the implications of our work?
***
1. Will it be possible to write an algorithm that is completly unbias ?
Falling back on the paragraph above, I'm wondering wether it will be possible in the future to have algorithms do work such as selecting an applicant without bias. Obviously a human interviewer would also have certain biases in an interview, which might be very different to a computer (e.g. a human would probably look much more at the appearance of the interviewee). But besides the huge gain in efficiency, a computer also has the opportunity to handle such a problem with complete objectivity, something a human could never do. 

2. Should such an algorithm handle problems completly objectively ?
The question above raised another question to me, wether an algorithm should actually be purely objective. A certain paramenter might logically indicate, that a certain applicant is better or worse suited for the position, but that parameter might be very unethical to use (e.g. the data might indicate that a certain relegion is better suited for the job, but this may only be due to a lack of available data and also it would be highly discriminating to hire a person over another person based on their religion). So the algorithm would have to be modified to take those kind of parameters out of consideration, but this leads back to question 1 wether such an algorithm could be implemented, since there is an unknown amount of those kinds of parameters. Also the choice of the acceptibility of a parameter is again subjective, since it is made by humans...
***
1. How widely is the deom checklist used at the moment? (Because the checklicst sound really interesting but do for example more profit oriented companies use such tools?)
1. Do they (DrivenData) only work with data scientists or also with people from other discipliens? And if so, how are these different backgrouds merged within the process? (Because it sound a bit like the team is mostly composed of computer scientists.)
***
The question I came up with is based on the ideo of untrustworthy data. The question was triggered by the following statement: “You have to distinguish between trustworthy data and data you cannot trust”. I do have a hard time understanding how one cannot trust the empirically gathered data when the data is based on your own observations by going out and surveying the consumers behavior. Although I'm aware that there might be certain measure inaccuracies, I believe that getting a wide-ranged overview of consumers behavior is a perfectly acceptable data foundation.
***
1. How does the cookie cutter data science project work? Sounded really interesting to me.
1. Why is access to Data Science as a field still so hard for non-computer scientists if the data science community keeps highlighting that a "Human-Centered" approach is super important? Why isn't there more emphasize on training professionals from "Human-Centered" fields in data science methodology?
***
1. I was asking myself it can really be that easy said that you always need to get to where your data originates from.
This is easier said than done as sometimes data can be generated where you are not permitted to be on site. The example
of the tanzania finance data is one of them. Not everyone or everywhere people are willing to let you observe money transactions.
***
1. I am interested in the bias problem mentioned in the podcast. Bias can be generated however by algorithm itself as well as in the data collection process. Besides obervation of data collection, is there any method to detect bias in data or in algorithm and how to prevent the problem?