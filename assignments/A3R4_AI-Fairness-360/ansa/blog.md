# Title of your post
> **Date:** 24.11.2020 - 15:23 PM *(Due: 01.12.2020 - 03:00 PM)*
> **Name:** `ansa` Anil S.
> **Session:** [04 Exercise - Fairness](https://github.com/FUB-HCC/hcds-winter-2020/wiki/04_exercise)   
----

## R4 - Reflection
> Democast: Mitigating Discrimination and Bias with AI Fairness 360 - Democast #5

### 🗨️&nbsp; "How does the video inform your understanding of human-centered data science?"  
I learned how different algorithms mitigate biases. That fairness is an important metric for human centered data science. And that ironically AI itself can support us to try to eliminate as much discrimination as possible.

### ❓&nbsp; Questions
1. Can we guarantee that the AI's like the Fairness AI 360 will stay as unbiased as possible in the future ?
1. Is AI the best possible way to solve this problem ?

***

## A3 - Wikipedia, ORES, and BIAS
Please, put everything regarding `A3` into the `blog.md` file of last week!

[Assignment 3](https://github.com/FUB-HCC/hcds-winter-2020/blob/main/assignments/A3_Bias/ansa/blog.md)
