# Reflection 5
> **Name:** `xiyu` Xin Y.
> **Session:** [05 Exercise - Transparency](https://github.com/FUB-HCC/hcds-winter-2020/wiki/05_exercise)   
----

## R5 - Reflection
> **Date:** 07.12.2020 - 11:47 AM *(Due: 08.12.2020 - 03:00 PM)*<br>
> **Book:** "Interpretable machine learning. A Guide for Making Black Box Models Explainable" by Molnar

### üó®Ô∏è&nbsp; "How does the reading inform your understanding of human-centered data science?"  
_Answer in at least 2-3 complete sentences_

Interpretability can be offered through different methods regarding different respects. And various interpretation methods can be categorized regarding to different criterien. 
Intrisic method for interpretation is normally model specific and is closely related to model features, where as post hoc methods is normally applied after model training and provides more flexibility. On the other hand, the various interpretation methods can also be differentiated according to their results. Some interpretation methods may share common features are related with one other. 

### ‚ùì&nbsp; Questions
1. I am still a little bit confused on difference between explanations and interpretations. In the chapter 2.2 (or generally chapter 2), it seems that the author use them as synonyms. 
<br>**Why:** I have read some general papers on XAI which describes interpretability as intrinsic explanability, therefore, it seems that interpretability is subconcept of explanability. I am unsure how to clearly differentiate them apart from each other or they are actually the synonyms. 

1. Is there any difference between interpretability or interpretation methods for parametric and non-parametric learning models? <br>**Why:** This question is interesting for me because some interpretation methods are based on parametric statistics, and I am wondering if there is something we need to consider of when choose an interpretation method. 

***

## A4 - Transparency
> **Date:** 10.12.2020 - 20:09 PM *(Due: 14.12.2020 - 12:00 PM)*<br>
> Group: PERSON1 and PERSON2<br>
> Model: NAME OF MODEL<br>

### Summary 

_Please summarize your findings and analyses regarding (1) general understanding, (2) API, (3) ML algorithm and training/test data, and (4) features._

### Openness
...

### Intrinsic interpretability
...

### Algorithmic transparency
...

### Conclusion
_From a human-centered perspective - what do you think about your model and ORES in general?_
