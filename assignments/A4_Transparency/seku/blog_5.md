# Assignment 5
> **Name:** `seku` Sebastian K.
> **Session:** [05 Exercise - Transparency](https://github.com/FUB-HCC/hcds-winter-2020/wiki/05_exercise)   
----

## R5 - Reflection
> **Date:** 07.12.2020 - 01:00 PM *(Due: 08.12.2020 - 03:00 PM)*<br>
> **Book:** "Interpretable machine learning. A Guide for Making Black Box Models Explainable" by Molnar

### ðŸ—¨ï¸&nbsp; "How does the reading inform your understanding of human-centered data science?"  
There are various methods for machine learning interpretability that can be classified according to specific criteria. First of all there is the distinction between intrinsic,
which achieves interpretability by restricting the model in its complexity, and post hoc, where results of a model are analysed to achieve interpretability. There are also various
methods to interpret the results, such as Feature summary statistic, Feature summary visualization, etc. There are also model specific or model agnostic tools for creating transparency.

### â“&nbsp; Questions
1. Shouldn't intrinsic interpretability always be the best case for a machine learning model? 

**Why:** 
Reducing complexity of a model isn't always easy but in my oppinion a goal for a good model should always be the least amount of complexity.

***

## A4 - Transparency
> **Date:** DD.MM.YYYY - HH:MM PM *(Due: 08.12.2020 - 03:00 PM)*<br>
> Group: PERSON1 and PERSON2<br>
> Model: NAME OF MODEL<br>

### Summary 

_Please summarize your findings and analyses regarding (1) general understanding, (2) API, (3) ML algorithm and training/test data, and (4) features._

### Openness
...

### Intrinsic interpretability
...

### Algorithmic transparency
...

### Conclusion
_From a human-centered perspective - what do you think about your model and ORES in general?_
