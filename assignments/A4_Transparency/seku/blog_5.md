# Assignment 5
> **Name:** `seku` Sebastian K.
> **Session:** [05 Exercise - Transparency](https://github.com/FUB-HCC/hcds-winter-2020/wiki/05_exercise)   
----

## R5 - Reflection
> **Date:** 07.12.2020 - 01:00 PM *(Due: 08.12.2020 - 03:00 PM)*<br>
> **Book:** "Interpretable machine learning. A Guide for Making Black Box Models Explainable" by Molnar

### 🗨️&nbsp; "How does the reading inform your understanding of human-centered data science?"  
There are various methods for machine learning interpretability that can be classified according to specific criteria. First of all there is the distinction between intrinsic,
which achieves interpretability by restricting the model in its complexity, and post hoc, where results of a model are analysed to achieve interpretability. There are also various
methods to interpret the results, such as Feature summary statistic, Feature summary visualization, etc. There are also model specific or model agnostic tools for creating transparency.

### ❓&nbsp; Questions
1. Shouldn't intrinsic interpretability always be the best case for a machine learning model? 

**Why:** 
Reducing complexity of a model isn't always easy but in my oppinion a goal for a good model should always be the least amount of complexity.

***

## A4 - Transparency
> **Date:** DD.MM.YYYY - HH:MM PM *(Due: 08.12.2020 - 03:00 PM)*<br>
> Group: Jonas W. and Sebastian K.<br>
> Model: drafttopic<br>

### Summary 

#### (1) general understanding 
The drafttopic model is designed to route newly created articles based on their apparent topical nature to interested reviewers. This is useful, because one of the biggest difficulies with reviewing new articles is finding someone appropriate to do this task. Due to a a gigantic variety of topics on Wikipedia, reviewers have to be picked accordingly to their skills and knowlegde to judge notability, relevance, and accuracy of an article. 
The drafttopic model can be used by anyone due to the fact that it is open source. Most probably it is used mostly by data scientists. Stakeholders are for example people that are releasing content on wikipedia or want to understand user activity on the website.
This is equally useful for Wikipedia and users on the website, because by redirecting new articles to suitable reviewers, the overall quality of information is more likely to increase.
The model is used only within enwiki.

#### (2) API 
The API has several different API calls that give information about specific models. One can check where a model is being used (with its used version) and then analyse the use in those specific projects. Then more detailed information can be retrieved like environment of the model, used params, the score_schema and different statistics. The API also allows to check the data for specific revisions.

#### (3) ML algorithm and training/test data 
#### (4) features

### Openness
...

### Intrinsic interpretability
...

### Algorithmic transparency
...

### Conclusion
_From a human-centered perspective - what do you think about your model and ORES in general?_
