{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course Human-Centered Data Science ([HCDS](https://www.mi.fu-berlin.de/en/inf/groups/hcc/teaching/winter_term_2020_21/course_human_centered_data_science.html)) - Winter Term 2020/21 - [HCC](https://www.mi.fu-berlin.de/en/inf/groups/hcc/index.html) | [Freie UniversitÃ¤t Berlin](https://www.fu-berlin.de/)\n",
    "\n",
    "***\n",
    "\n",
    "# A4 - Transparency\n",
    "Please use the follwing structure as a starting point. Extend and change the notebook according to your needs. This structure should help you to guide you through your analysis. This notebook is the foundation for condensing your results and writing your reflection in the end. So please read what we expect from you regarding the reflection first to structure your analysis accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] General understanding\n",
    "> What is the model about and who is using it?\n",
    "\n",
    "* What is your model about?\n",
    "* Why is this model useful?\n",
    "* Who is using this model?\n",
    "* What are stakeholder or users of ORES?\n",
    "* Why is this model useful to wikipedia?\n",
    "* What applications/projects/... within wikipedia are using this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] API\n",
    "> What does the ORES API (v3) tell you about a specific model? What functions does the API offer?\n",
    "\n",
    "Use the API to investigate your model: https://ores.wikimedia.org/v3/#/. What do the follwing API calls do and what do they tell you about your model?\n",
    "\n",
    "* `https://ores.wikimedia.org/v3/scores/`\n",
    "* `https://ores.wikimedia.org/v3/scores/?model_info`\n",
    "* `https://ores.wikimedia.org/v3/scores/enwiki`\n",
    "* `https://ores.wikimedia.org/v3/scores/enwiki?models=YOURMODELNAME&model_info`\n",
    "* `https://ores.wikimedia.org/v3/scores/enwiki?models=YOURMODELNAME&revids=SOMEIDHERE`\n",
    "* `https://ores.wikimedia.org/v3/scores/enwiki/REVID/YOURMODELNAME?model_info`\n",
    "* `https://ores.wikimedia.org/v3/scores/enwiki/REVID/YOURMODELNAME?features=true`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Injection\n",
    "Please check out the _feature injection_ feature of ORES: https://www.mediawiki.org/wiki/ORES/Feature_injection\n",
    "\n",
    "**Example:**\n",
    "\n",
    "     # Here you can get the perdiction for a revision, if the user would habe been anonymous:\n",
    "     https://ores.wikimedia.org/v3/scores/enwiki/991397091/damaging?features&feature.revision.user.is_anon=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] ML algorithm and training/test data\n",
    "> Which machine learning model is underlying and what data is used to build the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check out `model_info` in detail.\n",
    "* What does it tell you about the model performance?\n",
    "* You can visualise and explain your results regarding model performance.\n",
    "* What data was used to train and test the model?\n",
    "* What machine learning algorithm is your model using? Please explain briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Customize these with your own information\n",
    "headers = {\n",
    "    'User-Agent': 'https://github.com/marisanest',\n",
    "    'From': 'marisa.f.nest@fu-berlin.de'\n",
    "}\n",
    "\n",
    "def get_model_info(headers):\n",
    "    \n",
    "    # Define the endpoint\n",
    "    endpoint = 'https://ores.wikimedia.org/v3/scores/enwiki?models={model}&model_info'\n",
    "\n",
    "    params = {\n",
    "        'model'   : 'damaging'\n",
    "    }\n",
    "\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check all info that we can get from the API endpoint about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_info = get_model_info(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does it tell you about the model performance? \n",
    "\n",
    "To answer this question we analized the different metrics given by the API about the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract statistics\n",
    "statistics = model_info['enwiki']['models']['damaging']['statistics'].copy()\n",
    "\n",
    "# split statistics into different subdomains\n",
    "count_statistics = statistics.pop('counts')\n",
    "confusion_matrix = count_statistics.pop('predictions')\n",
    "rate_statistics = statistics.pop('rates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we look into overall count statistics. It seams that the sample test dataset consists of a total of 19332 samples. These samples consist of 18585 false and 747 true labeled data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': {'false': 18585, 'true': 747}, 'n': 19332}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw count statistics from the API\n",
    "count_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we look into the rate statistics. These statistics infrom us about the distribution of true and false labeled data points within the whole population and within the sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>false</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>0.034</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       population  sample\n",
       "false       0.966   0.961\n",
       "true        0.034   0.039"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rate statistics from the API as data frame\n",
    "pd.DataFrame(rate_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance statistcs also include all needed values for a confusion matrix (see below) but it is not clear how to interpret these values correctly (e.g. which is the true positiv value, etc.). In the following you see the confusion matrix values from the API and a interpretet version as data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'false': {'false': 17875, 'true': 710}, 'true': {'false': 318, 'true': 429}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw confusion matrix values from the API\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positiv</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positiv</th>\n",
       "      <td>429</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>318</td>\n",
       "      <td>17875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positiv  Negative\n",
       "Positiv       429       710\n",
       "Negative      318     17875"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpreting API response and transform it to needed values \n",
    "true_positiv = confusion_matrix['true']['true']\n",
    "false_positiv = confusion_matrix['false']['true']\n",
    "true_negative = confusion_matrix['false']['false']\n",
    "false_negative = confusion_matrix['true']['false']\n",
    "\n",
    "# genreate data frame to visualize data\n",
    "pd.DataFrame(\n",
    "    data=[\n",
    "        {'Positiv': true_positiv, 'Negative': false_positiv}, \n",
    "        {'Positiv': false_negative, 'Negative': true_negative}\n",
    "    ], \n",
    "    index=['Positiv', 'Negative']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step we look into the actual performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for value in statistics.values():\n",
    "    data.append(\n",
    "        {\n",
    "            'labels_false': value['labels']['false'], \n",
    "            'labels_true': value['labels']['true'], \n",
    "            'micro': value['macro'], \n",
    "            'macro':  value['micro']\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this model the following 12 different performance metrics with their respectie values are provided:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels_false</th>\n",
       "      <th>labels_true</th>\n",
       "      <th>micro</th>\n",
       "      <th>macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!f1</th>\n",
       "      <td>0.433</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!precision</th>\n",
       "      <td>0.347</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!recall</th>\n",
       "      <td>0.574</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filter_rate</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fpr</th>\n",
       "      <td>0.426</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_rate</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_auc</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             labels_false  labels_true  micro  macro\n",
       "!f1                 0.433        0.973  0.703  0.451\n",
       "!precision          0.347        0.985  0.666  0.369\n",
       "!recall             0.574        0.962  0.768  0.588\n",
       "accuracy            0.949        0.949  0.949  0.949\n",
       "f1                  0.973        0.433  0.703  0.955\n",
       "filter_rate         0.057        0.943  0.500  0.087\n",
       "fpr                 0.426        0.038  0.232  0.412\n",
       "match_rate          0.943        0.057  0.500  0.913\n",
       "pr_auc              0.997        0.448  0.722  0.978\n",
       "precision           0.985        0.347  0.666  0.963\n",
       "recall              0.962        0.574  0.768  0.949\n",
       "roc_auc             0.924        0.924  0.924  0.924"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'For this model the following {len(statistics.keys())} different performance metrics with their respectie values are provided:')\n",
    "pd.DataFrame(data=data, index=statistics.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there are a lots of different measurements. The \"micro\" and \"macro\" columns describe two different algorithms how to calculate the average value, but we have no clue what the \"label_false\" and \"lable_true\" columns show us. Also some metrics are more clear than others. For example accuracy, precision, recall, f1, fpr (false positive rate) are well known metrics, but filter_rate, match_rate, pr_auc, roc_auc and all metrics with a \"!\" in front need some more inspection. \"!\" probably stands for \"negative\", e.g. negative precision which is an alias for negative predictive value (nvp).\n",
    "\n",
    "Depending on the metrics inspected, the model works in some cases quite good and in other cases rather poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What data was used to train and test the model?\n",
    "\n",
    "To answer this question we looked into the [ORES documentation](https://www.mediawiki.org/wiki/ORES) and found the follwong:\n",
    "\n",
    "> Advanced support\n",
    ">\n",
    "> Rather than assuming, we can ask editors to train ORES which edits are in-fact damaging and which edits look like they were saved in goodfaith. This requires additional work on the part of volunteers in the community, but it affords a more accurate and nuanced prediction with regards to the quality of an edit. Many tools will only function when advanced support is available for a target wiki.\n",
    "> \n",
    "> damaging â predicts whether or not an edit causes damage\n",
    "> \n",
    "> goodfaith â predicts whether an edit was saved in good-faith\n",
    "\n",
    "This informs us that the used training data for the damaging model was manually labeld by editors / volunteers of the specific wiki community. \n",
    "\n",
    "\n",
    "We also checked the MetaWiki dokumentation about ORES and the [damaging model](https://meta.wikimedia.org/wiki/Objective_Revision_Evaluation_Service/damaging). There again is described that the model is trained on human  judgement with a reference to the [Wiki label](https://meta.wikimedia.org/wiki/Wiki_labels) project [Edit quality](https://en.wikipedia.org/wiki/Wikipedia:Labels/Edit_quality) (see below). \n",
    "\n",
    "\n",
    "> This model was trained on human judgement for whether or not an edit is damaging.\n",
    "\n",
    "\n",
    "Therefore we checked the [Wiki labels documentation](https://meta.wikimedia.org/wiki/Wiki_labels). Wiki labels is a tool/service/gadget which is used by ORES to manage projects in which editors are invited to label data.\n",
    "\n",
    "Afterwards we looked deeper into the already mentioned Wiki label project within the english Wikipedia: [Edit quality](https://en.wikipedia.org/wiki/Wikipedia:Labels/Edit_quality). There is written:\n",
    "\n",
    "> We'll be using WP:Labels to review 6334 randomly sampled edits as \"damaging\" and/or \"good-faith\" in order to train classifiers for mw:ORES. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What machine learning algorithm is your model using?\n",
    "\n",
    "To get more information about the algorithm used for training and all dependent metrices, we look into different aspects of the API response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GradientBoosting'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['enwiki']['models']['damaging']['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friedman_mse'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['enwiki']['models']['damaging']['params']['criterion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deviance'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['enwiki']['models']['damaging']['params']['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'prediction': {'description': 'The most likely label predicted by the estimator',\n",
       "   'type': 'boolean'},\n",
       "  'probability': {'description': 'A mapping of probabilities onto each of the potential output labels',\n",
       "   'properties': {'false': {'type': 'number'}, 'true': {'type': 'number'}},\n",
       "   'type': 'object'}},\n",
       " 'title': 'Scikit learn-based classifier score with probability',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['enwiki']['models']['damaging']['score_schema']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can see ist, that as trainng algorithm **gradient boosting** ist used.\n",
    "\n",
    "Gradient boosting is definied as:\n",
    "\n",
    "> Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function. [1]\n",
    "\n",
    "That means that different underlying base algorithms can be used (such as decision trees). Thus for our case it is not clear which algorithm is used for the our model.\n",
    "\n",
    "Additioanl we can see that as loss function **deviance** and as criterion **friedman mean squared error** are implemented.\n",
    "\n",
    "The loss function defines a function which caluculates a values that shows how good or bad the current model works. The task of the used trainng algorithm is then to maximize or minimize the outcome of the loss function.\n",
    "\n",
    "As far as we understand the term criterion, it is just a synonym for loss function. But it doesn't make sense to have to different loss functions, so we are not sure how to deal with this info. \n",
    "\n",
    "Another info the API gives us is about the used scoring schema. It describes that a scikit learn-based classifier is used to map the outcome of the gradient boosting algorithm to probabilities for each potential output label and that the finally predicted label is then the most likely label. This is just an interpretation of us, we are not sure if this is the correct understanding of the provided info.\n",
    "\n",
    "1 [Gradient_boosting](https://en.wikipedia.org/wiki/Gradient_boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Features\n",
    "> Which features are used and which have the greatest influence on the prediction?\n",
    "\n",
    "* What features is your model using?\n",
    "* What do they mean?\n",
    "* Which is the most important features?\n",
    "* `https://ores.wikimedia.org/v3/scores/enwiki/991379667/articlequality?features=true`\n",
    "* Are all models (in all languages of wikipedia), are they using the same features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What features is your model using?\n",
    "\n",
    "To get an answere to this question, we retrive the features info for one sample revision via the API and features=true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_info(headers, rev_id, project='enwiki'):\n",
    "    \n",
    "    # Define the endpoint\n",
    "    endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/{rev_id}/{model}?features=true'\n",
    "    \n",
    "    params = {\n",
    "        'project' : project,\n",
    "        'model'   : 'damaging',\n",
    "        'rev_id'  : rev_id\n",
    "    }\n",
    "\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "\n",
    "    return response[project]['scores'][str(rev_id)]['damaging']['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_info = get_feature_info(headers, 991379667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature.english.badwords.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.english.badwords.revision.diff.match_delta_increase': 0,\n",
       " 'feature.english.badwords.revision.diff.match_delta_sum': 0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.english.dictionary.revision.diff.dict_word_delta_decrease': -1,\n",
       " 'feature.english.dictionary.revision.diff.dict_word_delta_increase': 0,\n",
       " 'feature.english.dictionary.revision.diff.dict_word_delta_sum': -1,\n",
       " 'feature.english.dictionary.revision.diff.dict_word_prop_delta_decrease': -0.00045392646391284613,\n",
       " 'feature.english.dictionary.revision.diff.dict_word_prop_delta_increase': 0.0,\n",
       " 'feature.english.dictionary.revision.diff.dict_word_prop_delta_sum': -0.00045392646391284613,\n",
       " 'feature.english.dictionary.revision.diff.non_dict_word_delta_decrease': 0,\n",
       " 'feature.english.dictionary.revision.diff.non_dict_word_delta_increase': 0,\n",
       " 'feature.english.dictionary.revision.diff.non_dict_word_delta_sum': 0,\n",
       " 'feature.english.dictionary.revision.diff.non_dict_word_prop_delta_decrease': 0.0,\n",
       " 'feature.english.dictionary.revision.diff.non_dict_word_prop_delta_increase': 0.0,\n",
       " 'feature.english.dictionary.revision.diff.non_dict_word_prop_delta_sum': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.english.informals.revision.diff.match_delta_increase': 0,\n",
       " 'feature.english.informals.revision.diff.match_delta_sum': 0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.len(<datasource.tokenized(datasource.revision.parent.text)>)': 139775.0,\n",
       " 'feature.len(<datasource.tokenized(datasource.revision.text)>)': 139774.0,\n",
       " 'feature.len(<datasource.wikitext.revision.markups>)': 14437.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.markups>)': 14437.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.uppercase_words>)': 705.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.words>)': 52642.0,\n",
       " 'feature.len(<datasource.wikitext.revision.words>)': 52641.0,\n",
       " 'feature.revision.comment.has_link': True,\n",
       " 'feature.revision.comment.suggests_section_edit': False,\n",
       " 'feature.revision.diff.longest_new_repeated_char': 1,\n",
       " 'feature.revision.diff.longest_new_token': 1,\n",
       " 'feature.revision.page.is_articleish': True,\n",
       " 'feature.revision.page.is_draftspace': False,\n",
       " 'feature.revision.page.is_mainspace': True,\n",
       " 'feature.revision.user.has_advanced_rights': False,\n",
       " 'feature.revision.user.is_admin': False,\n",
       " 'feature.revision.user.is_anon': False,\n",
       " 'feature.revision.user.is_bot': False,\n",
       " 'feature.revision.user.is_curator': False,\n",
       " 'feature.revision.user.is_patroller': False,\n",
       " 'feature.revision.user.is_trusted': False,\n",
       " 'feature.temporal.revision.user.seconds_since_registration': 237066577,\n",
       " 'feature.wikitext.revision.chars': 498512.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.external_links': 1014.0,\n",
       " 'feature.wikitext.revision.headings': 107.0,\n",
       " 'feature.wikitext.revision.parent.chars': 498515.0,\n",
       " 'feature.wikitext.revision.parent.external_links': 1014.0,\n",
       " 'feature.wikitext.revision.parent.headings': 107.0,\n",
       " 'feature.wikitext.revision.parent.ref_tags': 1103.0,\n",
       " 'feature.wikitext.revision.parent.tags': 1229.0,\n",
       " 'feature.wikitext.revision.parent.templates': 1194.0,\n",
       " 'feature.wikitext.revision.parent.wikilinks': 1966.0,\n",
       " 'feature.wikitext.revision.ref_tags': 1103.0,\n",
       " 'feature.wikitext.revision.tags': 1229.0,\n",
       " 'feature.wikitext.revision.templates': 1194.0,\n",
       " 'feature.wikitext.revision.wikilinks': 1966.0}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model is using the above listed 78 different features (we also checked other revisions and they all seem to have 78 features). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do they mean?\n",
    "\n",
    "For some features it is easy to guess (using the above listed feture-key-name) what the feature is about. For exapmle 'feature.revision.user.is_anon' will probably a boolean flag which describes if the user who did this revision was an anonymous user or not. Other features are not very self-explanatory like 'feature.english.informals.revision.diff.match_prop_delta_sum'. It also easy to see that the feature-key-names some structure, so that you can get some idea about the domain the feature deals with. For example all features which start with 'feature.revision.user' belong to user specific measurements. Here a little description table:\n",
    "\n",
    "| domain                                   | description                                                                                                                                                                                                                                                                                                                               |\n",
    "|:------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| feature.english.badwords.revision.diff   | These features deal with new added or removed bad words or BWDS (see [BWDS](https://www.mediawiki.org/wiki/ORES/BWDS_review)). Therefore the difference between the old revision and the new one are compared. It is not clear what exactly the different features measure (e.g. match_prop_delta_sum).                                      |\n",
    "| feature.english.dictionary.revision.diff | These features deal with new added or removed words which are known from a specific dictionary (see [Word lists](https://meta.wikimedia.org/wiki/Research:Revision_scoring_as_a_service/Word_lists)). Therefore the difference between the old revision and the new one are compared. It is not clear what exactly the different features measure (e.g. dict_word_prop_delta_sum). |\n",
    "| feature.english.informals.revision.diff  | These features deal with new added or removed infromal words which are known from a specific dictionary (see [Word lists](https://meta.wikimedia.org/wiki/Research:Revision_scoring_as_a_service/Word_lists)). Therefore the difference between the old revision and the new one are compared. It is not clear what exactly the different features measure (e.g. dict_word_prop_delta_decrease).                                                                                                                                                                                                                                                                                              |\n",
    "| feature.len                              | These feature measure different length, e.g. datasource.wikitext.revision.words probably measures the amount of words of the revision's wikitext.                                                                                                                                                                                         |\n",
    "| feature.revision.comment                 | These features deal with the revision comment.                                                                                                                                                                                                                                                                                            |\n",
    "| feature.revision.diff                    | These features deal with the difference between the current and previous revision.                                                                                                                                                                                                                                                        |\n",
    "| feature.revision.page                    | These features deal with the page that is edited by the revision.                                                                                                                                                                                                                                                                         |\n",
    "| feature.revision.user                    | These features deal with the user that has made the revision.                                                                                                                                                                                                                                                                             |\n",
    "| feature.temporal.revision.user           | These features also deal with the user that has made the revision.                                                                                                                                                                                                                                                                        |\n",
    "| feature.wikitext.revision                | These features deal with the wikitext of the revision. This probably means the actual text of the edited page and not the meta data.                                                                                                                                                                                                      |\n",
    "\n",
    "All in all we can summarise that these features ar not very well explained. We can guess the meaning of some of them but we can not be sure if this is the correct interpretation. We could also check the revision and than try to see if out interpretation and the values seen above for a specific feature correspond to the actual revison. But this is really unhandy. We also searched for more infromation but we didn't find anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which is the most important features?\n",
    "\n",
    "This question can not be answerd properly so far. We tried to change each feature value seperately and then measured the resulting predictet probability distribution. We then compared the differences between these probability distributions and the baseline probability (the probability without changing any feature value) with the jensen shannon dinstance. But the problem is that the model always uses all features. So when we set a value to 0 or change a value from 0 to 100 or set a False value to True, these changes can not be comapred. To be able to really compare the outputs we need to be able to exclude features from the prediction completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability(headers, rev_id, feature=None, model='damaging', project='enwiki'):\n",
    "    \n",
    "    # Define the endpoint\n",
    "    endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/{rev_id}/{model}?features&{feature}=None'\n",
    "    \n",
    "    params = {\n",
    "        'project' : project,\n",
    "        'model'   : model,\n",
    "        'feature' : feature, #'' if feature is None else f'&{feature}',\n",
    "        'rev_id'  : rev_id\n",
    "    }\n",
    "\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "\n",
    "    return response# [project]['scores'][str(rev_id)][model]['score']['probability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some test and playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rev_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_probability = get_probability(headers, rev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_probabilities = {}\n",
    "#\n",
    "# for key in feature_info.keys():\n",
    "#    feature_probabilities[key] = get_probability(headers, rev_id, feature=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_probability_distances = {}\n",
    "\n",
    "# for key, value in feature_probabilities.items():\n",
    "#    feature_probability_distances[key] = distance.jensenshannon(list(value.values()), list(base_probability.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(feature_probability_distances.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are all models (in all languages of wikipedia), are they using the same features?\n",
    "\n",
    "To answer this question we check out other Wikipedia language version that support this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature.english.badwords.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.english.badwords.revision.diff.match_delta_increase': 0,\n",
       " 'feature.english.badwords.revision.diff.match_delta_sum': 0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.english.informals.revision.diff.match_delta_increase': 0,\n",
       " 'feature.english.informals.revision.diff.match_delta_sum': 0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.french.badwords.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.french.badwords.revision.diff.match_delta_increase': 0,\n",
       " 'feature.french.badwords.revision.diff.match_delta_sum': 0,\n",
       " 'feature.french.badwords.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.french.badwords.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.french.badwords.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.french.dictionary.revision.diff.dict_word_delta_decrease': 0,\n",
       " 'feature.french.dictionary.revision.diff.dict_word_delta_increase': 46,\n",
       " 'feature.french.dictionary.revision.diff.dict_word_delta_sum': 46,\n",
       " 'feature.french.dictionary.revision.diff.dict_word_prop_delta_decrease': 0.0,\n",
       " 'feature.french.dictionary.revision.diff.dict_word_prop_delta_increase': 46.0,\n",
       " 'feature.french.dictionary.revision.diff.dict_word_prop_delta_sum': 46.0,\n",
       " 'feature.french.dictionary.revision.diff.non_dict_word_delta_decrease': 0,\n",
       " 'feature.french.dictionary.revision.diff.non_dict_word_delta_increase': 5,\n",
       " 'feature.french.dictionary.revision.diff.non_dict_word_delta_sum': 5,\n",
       " 'feature.french.dictionary.revision.diff.non_dict_word_prop_delta_decrease': 0.0,\n",
       " 'feature.french.dictionary.revision.diff.non_dict_word_prop_delta_increase': 5.0,\n",
       " 'feature.french.dictionary.revision.diff.non_dict_word_prop_delta_sum': 5.0,\n",
       " 'feature.french.informals.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.french.informals.revision.diff.match_delta_increase': 0,\n",
       " 'feature.french.informals.revision.diff.match_delta_sum': 0,\n",
       " 'feature.french.informals.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.french.informals.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.french.informals.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.len(<datasource.tokenized(datasource.revision.parent.text)>)': 0.0,\n",
       " 'feature.len(<datasource.tokenized(datasource.revision.text)>)': 119.0,\n",
       " 'feature.len(<datasource.wikitext.revision.markups>)': 10.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.markups>)': 0.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.uppercase_words>)': 0.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.words>)': 0.0,\n",
       " 'feature.len(<datasource.wikitext.revision.words>)': 51.0,\n",
       " 'feature.revision.comment.has_link': False,\n",
       " 'feature.revision.comment.suggests_section_edit': False,\n",
       " 'feature.revision.diff.longest_new_repeated_char': 3,\n",
       " 'feature.revision.diff.longest_new_token': 9,\n",
       " 'feature.revision.page.is_articleish': True,\n",
       " 'feature.revision.page.is_draftspace': False,\n",
       " 'feature.revision.page.is_mainspace': True,\n",
       " 'feature.revision.user.has_advanced_rights': False,\n",
       " 'feature.revision.user.is_admin': False,\n",
       " 'feature.revision.user.is_anon': False,\n",
       " 'feature.revision.user.is_bot': False,\n",
       " 'feature.revision.user.is_curator': False,\n",
       " 'feature.revision.user.is_patroller': False,\n",
       " 'feature.revision.user.is_trusted': False,\n",
       " 'feature.temporal.revision.user.seconds_since_registration': 31536000,\n",
       " 'feature.wikitext.revision.chars': 357.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_increase': 10.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_sum': 10.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_increase': 10.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_sum': 10.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_increase': 1.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_sum': 1.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_increase': 1.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_sum': 1.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.external_links': 0.0,\n",
       " 'feature.wikitext.revision.headings': 0.0,\n",
       " 'feature.wikitext.revision.parent.chars': 0.0,\n",
       " 'feature.wikitext.revision.parent.external_links': 0.0,\n",
       " 'feature.wikitext.revision.parent.headings': 0.0,\n",
       " 'feature.wikitext.revision.parent.ref_tags': 0.0,\n",
       " 'feature.wikitext.revision.parent.tags': 0.0,\n",
       " 'feature.wikitext.revision.parent.templates': 0.0,\n",
       " 'feature.wikitext.revision.parent.wikilinks': 0.0,\n",
       " 'feature.wikitext.revision.ref_tags': 0.0,\n",
       " 'feature.wikitext.revision.tags': 2.0,\n",
       " 'feature.wikitext.revision.templates': 0.0,\n",
       " 'feature.wikitext.revision.wikilinks': 3.0}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_info = get_feature_info(headers, 1, project='frwiki')\n",
    "feature_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature.english.badwords.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.english.badwords.revision.diff.match_delta_increase': 0,\n",
       " 'feature.english.badwords.revision.diff.match_delta_sum': 0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.english.badwords.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.english.informals.revision.diff.match_delta_increase': 0,\n",
       " 'feature.english.informals.revision.diff.match_delta_sum': 0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.english.informals.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.german.badwords.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.german.badwords.revision.diff.match_delta_increase': 0,\n",
       " 'feature.german.badwords.revision.diff.match_delta_sum': 0,\n",
       " 'feature.german.badwords.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.german.badwords.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.german.badwords.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.german.dictionary.revision.diff.dict_word_delta_decrease': 0,\n",
       " 'feature.german.dictionary.revision.diff.dict_word_delta_increase': 33,\n",
       " 'feature.german.dictionary.revision.diff.dict_word_delta_sum': 33,\n",
       " 'feature.german.dictionary.revision.diff.dict_word_prop_delta_decrease': 0.0,\n",
       " 'feature.german.dictionary.revision.diff.dict_word_prop_delta_increase': 33.0,\n",
       " 'feature.german.dictionary.revision.diff.dict_word_prop_delta_sum': 33.0,\n",
       " 'feature.german.dictionary.revision.diff.non_dict_word_delta_decrease': 0,\n",
       " 'feature.german.dictionary.revision.diff.non_dict_word_delta_increase': 7,\n",
       " 'feature.german.dictionary.revision.diff.non_dict_word_delta_sum': 7,\n",
       " 'feature.german.dictionary.revision.diff.non_dict_word_prop_delta_decrease': 0.0,\n",
       " 'feature.german.dictionary.revision.diff.non_dict_word_prop_delta_increase': 7.0,\n",
       " 'feature.german.dictionary.revision.diff.non_dict_word_prop_delta_sum': 7.0,\n",
       " 'feature.german.informals.revision.diff.match_delta_decrease': 0,\n",
       " 'feature.german.informals.revision.diff.match_delta_increase': 0,\n",
       " 'feature.german.informals.revision.diff.match_delta_sum': 0,\n",
       " 'feature.german.informals.revision.diff.match_prop_delta_decrease': 0.0,\n",
       " 'feature.german.informals.revision.diff.match_prop_delta_increase': 0.0,\n",
       " 'feature.german.informals.revision.diff.match_prop_delta_sum': 0.0,\n",
       " 'feature.len(<datasource.tokenized(datasource.revision.parent.text)>)': 0.0,\n",
       " 'feature.len(<datasource.tokenized(datasource.revision.text)>)': 89.0,\n",
       " 'feature.len(<datasource.wikitext.revision.markups>)': 0.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.markups>)': 0.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.uppercase_words>)': 0.0,\n",
       " 'feature.len(<datasource.wikitext.revision.parent.words>)': 0.0,\n",
       " 'feature.len(<datasource.wikitext.revision.words>)': 40.0,\n",
       " 'feature.revision.comment.has_link': False,\n",
       " 'feature.revision.comment.suggests_section_edit': False,\n",
       " 'feature.revision.diff.longest_new_repeated_char': 2,\n",
       " 'feature.revision.diff.longest_new_token': 12,\n",
       " 'feature.revision.page.is_articleish': True,\n",
       " 'feature.revision.page.is_draftspace': False,\n",
       " 'feature.revision.page.is_mainspace': True,\n",
       " 'feature.revision.user.has_advanced_rights': False,\n",
       " 'feature.revision.user.is_admin': False,\n",
       " 'feature.revision.user.is_anon': True,\n",
       " 'feature.revision.user.is_bot': False,\n",
       " 'feature.revision.user.is_curator': False,\n",
       " 'feature.revision.user.is_patroller': False,\n",
       " 'feature.revision.user.is_trusted': False,\n",
       " 'feature.temporal.revision.user.seconds_since_registration': 0,\n",
       " 'feature.wikitext.revision.chars': 257.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.markup_prop_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.number_prop_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_decrease': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_increase': 0.0,\n",
       " 'feature.wikitext.revision.diff.uppercase_word_prop_delta_sum': 0.0,\n",
       " 'feature.wikitext.revision.external_links': 0.0,\n",
       " 'feature.wikitext.revision.headings': 0.0,\n",
       " 'feature.wikitext.revision.parent.chars': 0.0,\n",
       " 'feature.wikitext.revision.parent.external_links': 0.0,\n",
       " 'feature.wikitext.revision.parent.headings': 0.0,\n",
       " 'feature.wikitext.revision.parent.ref_tags': 0.0,\n",
       " 'feature.wikitext.revision.parent.tags': 0.0,\n",
       " 'feature.wikitext.revision.parent.templates': 0.0,\n",
       " 'feature.wikitext.revision.parent.wikilinks': 0.0,\n",
       " 'feature.wikitext.revision.ref_tags': 0.0,\n",
       " 'feature.wikitext.revision.tags': 0.0,\n",
       " 'feature.wikitext.revision.templates': 0.0,\n",
       " 'feature.wikitext.revision.wikilinks': 0.0}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_info = get_feature_info(headers, 1, project='dewiki')\n",
    "feature_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the french and german version of the model has almost the same features, with the different, that is uses some additional language dependent features (e.g. all features that start with 'feature.french.badwords.revision.diff', 'feature.french.badwords.revision.diff' or 'feature.french.badwords.revision.diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Customize these with your own information\n",
    "headers = {\n",
    "    'User-Agent': 'https://github.com/YOUR-USER-NAME',\n",
    "    'From': 'YOUR-EMAIL@fu-berlin.de'\n",
    "}\n",
    "\n",
    "def get_ores_data(rev_id, headers):\n",
    "    \n",
    "    # Define the endpoint: This is an example!\n",
    "    endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'\n",
    "\n",
    "    params = {'project' : 'enwiki',\n",
    "              'model'   : 'YOUMODELNAME',\n",
    "              'revids'  : rev_id\n",
    "              }\n",
    "\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "    data = json.dumps(response)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Credits\n",
    "\n",
    "We release the notebooks under the [Creative Commons Attribution license (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
