# Assignment 3 - Bias
> **Date:** 14.11.2020 - 19:54 PM *(Due: 01.12.2020 - 03:00 PM)*
> **Name:** `albe` Ali Bektas
> **Session:** [03 Exercise - Bias](https://github.com/FUB-HCC/hcds-winter-2020/wiki/03_exercise)   
----

## R3 - Reflection
> Article: Algorithmic Profiling of Job Seekers in Austria: How Austerity Politics Are Made Effective

### üó®Ô∏è&nbsp; "How does the video inform your understanding of human centered data science?"  
_In at least 2-3 full sentences, answer the question "How does the video inform your understanding of human centered data science?"._

The main takeaway from this paper for me was that technical artefacts such as the model and the data for the model is not just a passive technical tool but gains agency through everyday use. From the reading of this paper I understand that these systems strengthening biases which are present in the real world as they produce categories produce categories using statistical methods on the data and imply meaning in 
a specific context. 
My understanding of human centered data science is to work on methods coping with these kind of biases in the favor of the humans 
and the society while creating data science solutions.


### ‚ùì&nbsp; Questions
_Using full sentences, list at least one question that this video raised in your mind, and say why it caused you to ask this question_

1. In the case of the AMS Algorithm the question arises in me if it is not more of a conceptual error in matter of how and for which 

purpose the system is used for then the output it generates? In our current society it is not a secret that some groups of people

are disadvantaged based on some attributes they have (or they get assigned). Isn't it good that the algorithm mirrors the reality? 

Could this information not be used to have a good impact on the society. For example the AMS reasons investigate the circumstances why 

these group of people has a lesser chance to get integrated to the job market and create initiatives to help them. 



There are groups of people where it is more obvious that they are disadvantaged int many situations (eg. Womans, Homosexuals, People with foreign sounding names). But there are maybe also groups where it is not so obvious that they for what reason ever disadvantaged. 

Because such as they live in the wrong street, their parents had not the a higher education and maybe some more which are not know.

If the system is designed to find such attributes to support these people I think it is a good thing that the algorithm points 

out such biases. The question then is still if this bias really in the reality or only in the data the algorithm is trains with. 

***

## A3 - Wikipedia, ORES, and BIAS

**Repository:** `<add link to our repo here>`

### Reflections and implications

Write about `350` words, reflecting on what you have learned, what you found, what (if anything) surprised üò≤ you about your findings, and/or what theories you have about why any biases might exist (if you find they exist). Please also include any questions this assignment raised for you about bias, Wikipedia, or machine learning.

_Your 350 words_

1. _Your question 1?_
1. _Your question 2?_

### Questions

Pleas answer the following questions with at least 2-3 sentences each.

1. What biases did you expect to find in the data (before you started working with it), and why?
    * _answer_
1. What (potential) sources of bias did you discover or introduce during data processing and analysis?
    * _answer_
1. What might your results suggest about (English) Wikipedia as a data source?
    * _answer_
1. What might your results suggest about the internet and global society in general?
    * _answer_
1. Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might create biased or misleading results, due to the inherent gaps and limitations of the data?
    * _answer_
1. Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might still be appropriate and useful, despite its inherent limitations and biases?
    * _answer_
1. How might a researcher supplement or transform this dataset to potentially correct for the limitations/biases you observed?
    * _answer_
