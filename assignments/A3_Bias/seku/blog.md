# Assignment 3 - Bias
> **Date:** 14.11.2020 - 19:54 PM *(Due: 01.12.2020 - 03:00 PM)*
> **Name:** `seku` Sebastian K.
> **Session:** [03 Exercise - Bias](https://github.com/FUB-HCC/hcds-winter-2020/wiki/03_exercise)   
----

## R3 - Reflection
> Article: Algorithmic Profiling of Job Seekers in Austria: How Austerity Politics Are Made Effective

### üó®Ô∏è&nbsp; "How does the video inform your understanding of human centered data science?"  
My takeaway from the articel is that as a system designer one has an enourmous responsibility in making a system unbiased while working with data. Already biased data can cause social inequality and also discrimination towards people of specific sex, gender or heritage. It is of great importance to prevent bias towards specific minorities or sub-groups of people in terms of their belonging to a structurally discriminated group. On thing that can help is transparency in system design, to enable development of fair systems that benefit the whole society.

### ‚ùì&nbsp; Questions
1. Would quality assurance methods such as reviews help prevent bias in data by transferring individual responsibility to an independent group of people? 
2. Is it perhaps necessary for teams of developers of a system to belong to minorities or discriminated groups themselves in order to develop an unbiased system, or could this task also be achieved by, for example, a committee of minorities engaged in reviews.

***

## A3 - Wikipedia, ORES, and BIAS

**Repository:** [kuzniarz/A3-hcds-hcc](https://github.com/kuzniarz/A3-hcds-hcc)

### Reflections and implications

Write about `350` words, reflecting on what you have learned, what you found, what (if anything) surprised üò≤ you about your findings, and/or what theories you have about why any biases might exist (if you find they exist). Please also include any questions this assignment raised for you about bias, Wikipedia, or machine learning.

_Your 350 words_

1. _Your question 1?_
1. _Your question 2?_

### Questions

Pleas answer the following questions with at least 2-3 sentences each.

1. What biases did you expect to find in the data (before you started working with it), and why?
    * _answer_
1. What (potential) sources of bias did you discover or introduce during data processing and analysis?
    * _answer_
1. What might your results suggest about (English) Wikipedia as a data source?
    * _answer_
1. What might your results suggest about the internet and global society in general?
    * _answer_
1. Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might create biased or misleading results, due to the inherent gaps and limitations of the data?
    * _answer_
1. Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might still be appropriate and useful, despite its inherent limitations and biases?
    * _answer_
1. How might a researcher supplement or transform this dataset to potentially correct for the limitations/biases you observed?
    * _answer_
