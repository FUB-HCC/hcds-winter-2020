# Assignment 3
> **Date:** 23.11.2020 - 21:50 PM *(Due: 01.12.2020 - 03:00 PM)*
> **Name:** `xiyu` Xin Yu.
> **Session:** [03 Exercise - Bias](https://github.com/FUB-HCC/hcds-winter-2020/wiki/03_exercise)   
----

## R3 - Reflection
> Article: Algorithmic Profiling of Job Seekers in Austria: How Austerity Politics Are Made Effective

### üó®Ô∏è&nbsp; "How does the video inform your understanding of human centered data science?"  
_In at least 2-3 full sentences, answer the question "How does the video inform your understanding of human centered data science?"._

1. Regarding to human centered data science, the algorithm cannot be only reviewed and assessed from a technical view, since the algorithm is used for assiting human decisions and used for benifiting humans. Therefore, we should always keep its its social impact in mind.
2. The article also reminds me of last section concerning reproducibility since it is criticized in this paper that the "the document fails to explicate the exact nature of the data collection, cleaning and stewardship practices". This definitely reduces the algorithms reliability and credibility. Without a completely data understanding as well as concious data preparation, social prejudice can be easily learned and even exaggerated by not-well-designed algorithm.

### ‚ùì&nbsp; Questions
_Using full sentences, list at least one question that this video raised in your mind, and say why it caused you to ask this question_

1. As mentioned in the article, the author criticized that the data collection and data cleaning processes are not well documented so that the data analytic process is not transperent and the algorithm may learn bias from data history. Combined with what we learned from the lecture, bias could be imitigated by conciouslly data preparation and increasing explanation as well as interpretability. But since human weselves all have somehow bias, to what extend can the algorithm/decision system REALLY "corrected" by human? 
1. Is there any evaluation metric for measuring bias? Should the algorithm be 0-tolerant towards bias or there is somehow acceptance rate? 
1. I assume we need to sacrifice some efficiency (or maybe even accuracy) for unbiased algorithm design, is there any tradeoff between the so-called "conflicting" goals?
1. How we differ bias and preference in a system? For example as a non-German native speaker I will be definitely disdvantaged when competing with a native speaker for a specific job such as journalist. I personally would not take it as bias/discrimination, it is just a specific preference for specific background/competencies. But still the algorithm outcome maybe considered as unfair if we use the statistical measure. In this case, what will we see as preference; what will we see as bias? Is there any discussion on this issue in academic/practices?

***

## A3 - Wikipedia, ORES, and BIAS

**Repository:** `<add link to our repo here>`

### Reflections and implications

Write about `350` words, reflecting on what you have learned, what you found, what (if anything) surprised üò≤ you about your findings, and/or what theories you have about why any biases might exist (if you find they exist). Please also include any questions this assignment raised for you about bias, Wikipedia, or machine learning.

_Your 350 words_

1. _Your question 1?_
1. _Your question 2?_

### Questions

Pleas answer the following questions with at least 2-3 sentences each.

1. What biases did you expect to find in the data (before you started working with it), and why?
    * _answer_
1. What (potential) sources of bias did you discover or introduce during data processing and analysis?
    * _answer_
1. What might your results suggest about (English) Wikipedia as a data source?
    * _answer_
1. What might your results suggest about the internet and global society in general?
    * _answer_
1. Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might create biased or misleading results, due to the inherent gaps and limitations of the data?
    * _answer_
1. Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might still be appropriate and useful, despite its inherent limitations and biases?
    * _answer_
1. How might a researcher supplement or transform this dataset to potentially correct for the limitations/biases you observed?
    * _answer_
