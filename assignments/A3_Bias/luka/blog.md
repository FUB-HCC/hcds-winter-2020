# Title of your post
> **Date:** 14.11.2020 - 19:54 PM *(Due: 01.12.2020 - 03:00 PM)*
> **Name:** `alsc` Alexa S.
> **Session:** [03 Exercise - Bias](https://github.com/FUB-HCC/hcds-winter-2020/wiki/03_exercise)   
----

## R3 - Reflection
> Video: The Trouble with Bias - NIPS 2017 Keynote - Kate Crawford #NIPS2017.

### üó®Ô∏è&nbsp; "How does the video inform your understanding of human centered data science?"  

My main takeaway from the article is that biases can't always be split up into different categories, to later be used by a program, to calculate a possible discimination tendency. As was mentioned in the text the amount of discrimination a woman of a certain heritage encounteres does not directly correlate to the discrimination a man with similar heritage might encounter. The data therefore implies that the amount of discrimination depends on all the different characteristics combined, rather than the sum of the discrimination due to certain characteristics.

For instance, an arabic woman without a university degree might be discriminated by 60% (due to her characteristics: female 20%, arabic 20%, no degree 20%), but that does not imply that an arabic woman with a university degree will be discriminated by 40%.

### ‚ùì&nbsp; Questions

* How much more bais is an reasonably well implemented algorithm (meaning it doesn't overly discriminate against large groups e.g. woman) compared to humans doing the same job and should a certain level of bias be acceptable in an algorithm, since it might at least be less bias than it's human counter part would be ?

* How much easier might it be to attack bias within alorithms, compared to attacking bias within the mindset of the many workers, that would otherwise do the job ?

***

## A3 - Wikipedia, ORES, and BIAS

**Repository:** `<add link to our repo here>`

### Reflections and implications

Write about `350` words, reflecting on what you have learned, what you found, what (if anything) surprised üò≤ you about your findings, and/or what theories you have about why any biases might exist (if you find they exist). Please also include any questions this assignment raised for you about bias, Wikipedia, or machine learning.

_Your 350 words_

1. _Your question 1?_
1. _Your question 2?_

### Questions

Pleas answer the following questions with at least 2-3 sentences each.

1. What biases did you expect to find in the data (before you started working with it), and why?
    * _answer_
1. What (potential) sources of bias did you discover or introduce during data processing and analysis?
    * _answer_
1. What might your results suggest about (English) Wikipedia as a data source?
    * _answer_
1. What might your results suggest about the internet and global society in general?
    * _answer_
1. Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might create biased or misleading results, due to the inherent gaps and limitations of the data?
    * _answer_
1. Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might still be appropriate and useful, despite its inherent limitations and biases?
    * _answer_
1. How might a researcher supplement or transform this dataset to potentially correct for the limitations/biases you observed?
    * _answer_
