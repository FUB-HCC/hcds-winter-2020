# Assignment 8 - Privacy and Security
> **Name:** `frra` Franziska R.
> **Session:** [11 Exercise - Privacy and Security](https://github.com/FUB-HCC/hcds-winter-2020/wiki/11_exercise)   
----

## Preparation

Franziska Boenisch is a research associate in applied and integrated security at Fraunhofer AISEC.  She is researching in the area of Differential Privacy at the moment. Her research interest lies at the intersection of Machine Learning (ML) and Data Privacy, as well as in the quantification of privacy loss and in the translation between a formal value of a privacy guarantees and real-world implications.

1. I was wondering if ML security and privacy policies can be somehow standardized? I know that this is dependant from the algorithm or data, but like the AI guidelines, there could be something general for the field of ML. 

2. Is there an human-centered model for usable security and privacy? Security and privacy mechanisms should not complicate workflows and should be transparent for the user


## Summary
_approximately 250 words_


## Mind Map


## Question
...?

## Takeways
...
