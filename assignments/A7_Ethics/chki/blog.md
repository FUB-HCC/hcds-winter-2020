# Artificial intelligence, it's impact and ethical concerns.
> **Name:** `chki` Christopher K .
> **Session:** [10 Exercise - Explanations](https://github.com/FUB-HCC/hcds-winter-2020/wiki/10_exercise)   
----

## Preparation
I'm taking the biography from the [page about the guest lecture](https://www.mi.fu-berlin.de/en/inf/groups/hcc/news/2021_01_25_guest_talk_michl.html) as I could not find anything better:

Susanne Michl is a Professor of Medical Humanities and Medical Ethics at Charité - Universitätsmedizin Berlin since 2017. Her research focuses on concepts of individualization/personalization in human medicine, their ethical implications in the past and the present, and narrative medicine with data/evidence-based medicine. As a clinical ethics consultant, she moderates difficult treatment decisions at the bedside. From an applied perspective, she is particularly interested in decision-making processes grounded in data and narrated life stories, values, and interactions among participants.

1. In the article it says "Yet, many data scientists do not use the language of ethics to talk about these practices."  What is the language of ethics and is it really expected of data scientists to be able to speak it?
1. The article mentioned three intuitive (informal) definitions of fairness (regarding predictions for recidivism). It was mentioned that "recent work has established that satisfying all three at the same time would be impossible in most situations; meeting two will mean failing to comply with the third". I am not sure if I fully understand the implications of the three different definitions: Does that mean that (in most cases), we are not able to build fair systems? Is it ethically justifiable to release a system with social impact that does not fulfill the requirements of all three definitions?


## Summary
_approximately 250 words_

The lecture dealt with the use of artificial intelligence in human medicine as well as resulting ethical concerns and possible chances.
Professor Michl described how our knowledge about the consequences of a technology increases over time but at the same time the possibility to shape and change established technologies decreases. Because of that, it is important to think about a system's impact and ethical concerns at an early stage. The field of tension between automatisation and autonomy was discussed as well as the role of autonomous systems. Professor Michl described autonomous systems as moral actors that have to conform to moral and etchical principles.
Using a dialog system for radiology as an example, she showed that technical requirements might not fit what is actually needed in practice, highlighting the importance of taking context information into account. Professor Michl continued, by talking about human-machine-relationhships. For this, she introduced responsibility as an ethical principle and trust as a social phenomenon. Different kinds of trust were introduced, how a person's face can increase the trust in a system that they stand for. Professor Michl presented many questions that help to critically think about an intelligent system (from an ethical point of view). These questions relate to the knowledge that is generated by a system and whether the gernerated knowledge really helps to make better decisions. She explained how narrative-based decision making process plays an important role in finding consensus between all steakholders in a clinical context. She continued, by talking about algorithmic decision making in uncertain situations and potential risks. The lecture was closed by a discussion on an intelligent system that supports deciding on whether a person should get a curative or palliative therapy.

## Mind Map

![](<chki>_mind-map.png)

## Question
I believe that psychological health, belief and will are important parts of fighting deseases. Is there any scientific work to support that? And if so, should an artificial intelligence use related parameters for decision making ? I assume, that these parameters are usually not taken into account. 

## Takeways
Which concepts or ideas presented in the guest lectures do you find useful for your data science practice? Why?

* For larger projects that potentially have a social impact, I would try to involve ethicists (if possible). I think it is important to consider their advice and concerns to build a good and justifiable system. This could also take away pressure from data scientists and developers since they otherwise might be forced to decide on things outside of their expertise.
* I might be worth including some of the mentioned questions into some ethic checklist that can help to think about a given project. For example: By introducing the system, what  parameters that are not quantifiable are pushed into the background? Which ways to gain insight are devalueated?"
* I liked the idea of reaching consensus between a machine and a human and making the decision making as transparent as possible as a part of it.





