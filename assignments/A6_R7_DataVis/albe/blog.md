# Reflection 7
> **Name:** `albe` Ali B.
> **Session:** [08 Exercise - Explanations](https://github.com/FUB-HCC/hcds-winter-2020/wiki/08_exercise)   
----

## R7 - Reflection


**Answer in at least 2-3 complete sentences the question "How does the reading inform your understanding of human-centered data science?"**<br>

I think the main issue by designing interfaces for interacting with AI-infused systems is described very well with by the following sentence: *"AI components are inherently inconsistent due to poorly understood probabilistic behaviors on nuances of tasks and settings learned over time."*. The researches from Microsoft and the University of Washington developed and evaluated Design Guidelines to cope with the probabilistic and inconsistent behavior of AI. By reading the Design Guidelines the Dialogue principles from `ISO 9241-110` especially `controllability`, `error tolerance` and `conformity with user expectations` came to my mind. I think the introduced Guidelines are a good source to check for tackling difficulties from AI-infuced systems for fullfilling these principles. 



**By reflecting on your sentences, list at least one question that occurred in your mind while reading, and explain your motivation for asking this question.**

<br>

By reading the guidelines I noticed that the AI-infuced system should give feedback in many places. For example in G11 and G16. In G16 

it is mentioned that the system should give this feedback *Immediately*. I wonder if this immediate feedback may could interrupt the user 

experience? 


## A6 - xxx
...