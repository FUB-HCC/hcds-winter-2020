# Guidelines for Human-AI Interaction
> **Name:** `goto` Gorgin T.
> **Session:** [08 Exercise - Explanations](https://github.com/FUB-HCC/hcds-winter-2020/wiki/08_exercise)   
----

## R7 - Reflection
Please read (at least!) page three of the paper [Guidelines for Human-AI Interaction](https://www.microsoft.com/en-us/research/uploads/prod/2019/01/Guidelines-for-Human-AI-Interaction-camera-ready.pdf) <sup>[1]</sup>.

> 1. Answer in at least 2-3 complete sentences the question _"How does the reading inform your understanding of human-centered data science?"_. </br>
> 2. By reflecting on your sentences, list at least one question that occurred in your mind while reading, and explain your motivation for asking this question.

##### **Topic:** The core of the paper is a set of _18 guidelines for Human-AI Interaction_ [which] _are grouped into four sections that prescribe how an AI system should behave upon initial interaction, as the user interacts with the system, when the system is wrong, and over time._<sup>[2]</sup>

The "humble" introduction from the blog<sup>[2]</sup>, stating that each guideline should be seen as a suggestion and the level of implementation can vary and change, reminded me  of the importance of _perception_: If I was to implement an AI into a system (actually, when creating any software), then I must not forget that my perception can be different to others. In conclusion, the guideline confirmed for me that for building better software, an important factor is scientific research on human perception (and _not_ my personal understanding of usability).

So, the 18 G's might come in handy, they all make sense and should be considered.


_Question/thought:_</br>
Not really about my own sentences: At first, I got G13 (_Learn from user behavior_) wrong. It says, that a core element of the software is supposed to use AI to incorporate user's decisions, like a route planner learns from what routes the user selects.
I thought it suggests to "extend the AI-system with more AI": The navigation system could also learn when I tend to miss directions (lame example: After work I am tired) and hence tell me instructions earlier, speak louder and slower etc., or tell my radio to play slower songs on Monday morning because I tend to speed then, etc.</br>
Could it be useful to reach into domains usually not part of the system?

Maybe that's silly but I found it interesting :) 
</br></br></br>

---


[1] S. Amershi et al., “Guidelines for Human-AI Interaction,” in Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, Glasgow, Scotland Uk, May 2019, pp. 1–13, doi: 10.1145/3290605.3300233.

[2] [Microsoft Research Blog](https://www.microsoft.com/en-us/research/blog/guidelines-for-human-ai-interaction-design/)
