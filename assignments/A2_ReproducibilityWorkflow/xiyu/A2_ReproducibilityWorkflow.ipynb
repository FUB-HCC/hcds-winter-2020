{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course Human-Centered Data Science ([HCDS](https://www.mi.fu-berlin.de/en/inf/groups/hcc/teaching/winter_term_2020_21/course_human_centered_data_science.html)) - Winter Term 2020/21 - [HCC](https://www.mi.fu-berlin.de/en/inf/groups/hcc/index.html) | [Freie Universität Berlin](https://www.fu-berlin.de/)\n",
    "***\n",
    "# A2 - Reproducibility Workflow\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your assignment is to create a graph that looks a lot like the one below one, starting from scratch, and following best practices for reproducible research.\n",
    "\n",
    "![wikipedia_pageViews_2008-2020.png](img/wikipedia_pageViews_2008-2020.png)\n",
    "\n",
    "## Before you start\n",
    "1. Read all instructions carefully before you begin.\n",
    "1. Read all API documentation carefully before you begin.\n",
    "1. Experiment with queries in the sandbox of the technical documentation for each API to familiarize yourself with the schema and the data.\n",
    "1. Ask questions if you are unsure about anything!\n",
    "1. When documenting your project, please keep the following questions in your mind:\n",
    "   * _If I found this GitHub repository, and wanted to fully reproduce the analysis, what information would I want?_\n",
    "   * _What information would I need?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1️⃣: Data acquisition\n",
    "In order to measure Wikipedia traffic from January 2008 until October 2020, you will need to collect data from two different APIs:\n",
    "\n",
    "1. The **Legacy Pagecounts API** ([documentation](https://wikitech.wikimedia.org/wiki/Analytics/AQS/Legacy_Pagecounts), [endpoint](https://wikimedia.org/api/rest_v1/#!/Pagecounts_data_(legacy)/get_metrics_legacy_pagecounts_aggregate_project_access_site_granularity_start_end)) provides access to desktop and mobile traffic data from December 2007 through July 2016.\n",
    "1. The **Pageviews API** ([documentation](https://wikitech.wikimedia.org/wiki/Analytics/AQS/Pageviews), [endpoint](https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end)) provides access to desktop, mobile web, and mobile app traffic data from July 2015 through last month.\n",
    "\n",
    "For each API, you need to collect data for all months where data is available and then save the raw results into five (3+2) separate `JSON`files (one file per API query type) before continuing to step 2.\n",
    "\n",
    "To get you started, you can use the following **sample code for API calls**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://public.paws.wmcloud.org/User:Jtmorgan/data512_a1_example.ipynb?format=raw\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "endpoint_legacy = 'https://wikimedia.org/api/rest_v1/metrics/legacy/pagecounts/aggregate/{project}/{access-site}/{granularity}/{start}/{end}'\n",
    "endpoint_pageviews = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/{project}/{access}/{agent}/{granularity}/{start}/{end}'\n",
    "\n",
    "# SAMPLE parameters for getting aggregated legacy view data \n",
    "# see: https://wikimedia.org/api/rest_v1/#!/Legacy_data/get_metrics_legacy_pagecounts_aggregate_project_access_site_granularity_start_end\n",
    "example_params_legacy = {\"project\" : \"en.wikipedia.org\",\n",
    "                 \"access-site\" : \"desktop-site\",\n",
    "                 \"granularity\" : \"monthly\",\n",
    "                 \"start\" : \"2001010100\",\n",
    "                # for end use 1st day of month following final month of data\n",
    "                 \"end\" : \"2018100100\"\n",
    "                    }\n",
    "\n",
    "# SAMPLE parameters for getting aggregated current standard pageview data\n",
    "# see: https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end\n",
    "example_params_pageviews = {\"project\" : \"en.wikipedia.org\",\n",
    "                    \"access\" : \"desktop\",\n",
    "                    \"agent\" : \"user\",\n",
    "                    \"granularity\" : \"monthly\",\n",
    "                    \"start\" : \"2001010100\",\n",
    "                    # for end use 1st day of month following final month of data\n",
    "                    \"end\" : '2018101000'\n",
    "                        }\n",
    "\n",
    "# Customize these with your own information\n",
    "headers = {\n",
    "    'User-Agent': 'https://github.com/yourusername',\n",
    "    'From': 'youremail@fu-berlin.de'\n",
    "}\n",
    "\n",
    "def api_call(endpoint,parameters):\n",
    "    call = requests.get(endpoint.format(**parameters), headers=headers)\n",
    "    response = call.json()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_monthly_pageviews = api_call(endpoint_pageviews, example_params_pageviews)\n",
    "example_monthly_pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_monthly_legacy = api_call(endpoint_legacy, example_params_legacy)\n",
    "example_monthly_legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `JSON`-formatted source data file must contain the complete and un-edited output of your API queries. The naming convention for the source data files is: `apiname_accesstype_firstmonth-lastmonth.json`. For example, your filename for monthly page views on desktop should be: `pagecounts_desktop-site_200712-202010.json`\n",
    "\n",
    "### Important notes❗\n",
    "1. As much as possible, we're interested in *organic* (user) traffic, as opposed to traffic by web crawlers or spiders. The Pageview API (but not the Pagecount API) allows you to filter by `agent=user`. You should do that.\n",
    "1. There is about one year of overlapping traffic data between the two APIs. You need to gather, and later graph, data from both APIs for this period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data processing\n",
    "\n",
    "You will need to perform a series of processing steps on these data files in order to prepare them for analysis. These steps must be followed exactly in order to prepare the data for analysis. At the end of this step, you will have a single `CSV`-formatted data file `en-wikipedia_traffic_200712-202010.csv` that can be used in your analysis (step 3) with no significant additional processing.\n",
    "\n",
    "* For data collected from the Pageviews API, combine the monthly values for `mobile-app` and `mobile-web` to create a total mobile traffic count for each month.\n",
    "* For all data, separate the value of `timestamp` into four-digit year (`YYYY`) and two-digit month (`MM`) and discard values for day and hour (`DDHH`).\n",
    "\n",
    "Combine all data into a single CSV file with the following headers:\n",
    "\n",
    "| year | month |pagecount_all_views|pagecount_desktop_views|pagecount_mobile_views|pageview_all_views|pageview_desktop_views|pageview_mobile_views|\n",
    "|------| ------|-------------------|-----------------------|----------------------|------------------|----------------------|---------------------|\n",
    "| YYYY | MM    |num_views          |num_views              |num_views             |num_views         |num_views             |num_views            | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analysis\n",
    "\n",
    "For this assignment, the \"analysis\" will be fairly straightforward: you will visualize the dataset you have created as a **time series graph**. Your visualization will track three traffic metrics: mobile traffic, desktop traffic, and all traffic (mobile + desktop). In order to complete the analysis correctly and receive full credit, your graph will need to be the right scale to view the data; all units, axes, and values should be clearly labeled; and the graph should possess a legend and a title. You must also generate a .png or .jpeg formatted image of your final graph.\n",
    "Please graph the data in your notebook, rather than using an external application!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Credits\n",
    "\n",
    "This exercise is slighty adapted from the course [Human Centered Data Science (Fall 2019)](https://wiki.communitydata.science/Human_Centered_Data_Science_(Fall_2019)) of [Univeristy of Washington](https://www.washington.edu/datasciencemasters/) by [Jonathan T. Morgan](https://wiki.communitydata.science/User:Jtmorgan).\n",
    "\n",
    "Same as the original inventors, we release the notebooks under the [Creative Commons Attribution license (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
