# Title of your post
> **Name:** `luka` Lukas Kaibel
> **Session:** [06 Exercise - Post-hoc Interpretability](https://github.com/FUB-HCC/hcds-winter-2020/wiki/06_exercise)   
----

## R6 - Reflection
> **Date:** 14.12.2020 - 23:59 PM *(Due: 15.12.2020 - 03:00 PM)*<br>
> **Podcast:** "Judea Pearl: Causal Reasoning, Counterfactuals, Bayesian Networks, and the Path to AGI" (Lex Fridman)

### üó®Ô∏è&nbsp; "How does the podcast inform your understanding of human-centered data science?"  

The podcast talked a lot about the relationship between cause and effect. I found it especially interesting, how difficult it appearently is to teach a model to "think" counter causal, meaning that given a cause and a certain outcome, the model has to inferr their relationship itself, for example if the output changes. It was also discussed whether is is even possible for the current trend in AI algorithms to become fully self-thinking. In addition very generall questions about intellegence and the potential "illusion" of free will were debated. 

### ‚ùì&nbsp; Questions

1. Is there such a thing as actual free will, or is it really just an illusion, that we let ourselves believe is true ?
2. Why is it so hard for machines / models to follow back a given causal "line", and inferr causes for other, but related outputs ?
3. Is intellegence only about how much knowlegde is available and how well it can be merged together to create new knowledge ?

## A4 - Transparency
Please, put everything regarding `A4` into the `blog.md` file of last week!
